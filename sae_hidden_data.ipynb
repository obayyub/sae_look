{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x119848e70>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 73930.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#generate data for training as hidden state activations via LRH - sum of sparse overcomplete feature directions\n",
    "\n",
    "def generate_hidden_data(dim = 128, n_features = 512, \n",
    "                         n_samples = (2**10), sparsity = 10):\n",
    "    #basically want features Y times random vector w where w is sparse, then sum resulting vectors for hidden state\n",
    "    #overcomplete feature basis?\n",
    "    features = np.random.randn(n_features, dim)\n",
    "    features = features / np.linalg.norm(features, axis=1, keepdims=True)\n",
    "\n",
    "    #init sparsity weights\n",
    "    weights = np.zeros((n_samples, n_features))\n",
    "    #generate sparsity weights\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        active_feats = np.random.choice(n_features, size=sparsity, replace=False)\n",
    "        weights[i, active_feats] = np.random.randn(sparsity)\n",
    "    #make hidden data via sum of sparse features\n",
    "    hidden_data = weights @ features\n",
    "\n",
    "    return torch.tensor(hidden_data, dtype=torch.float32)\n",
    "\n",
    "print(generate_hidden_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self, input_dim, width_ratio=4, activation=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.sae_hidden = input_dim * width_ratio\n",
    "        self.W_in = nn.Parameter(\n",
    "            nn.init.kaiming_uniform_(\n",
    "                torch.empty(input_dim, self.sae_hidden), nonlinearity=\"relu\"\n",
    "            )\n",
    "        )\n",
    "        self.b_in = nn.Parameter(torch.zeros(self.sae_hidden))\n",
    "        self.W_out = nn.Parameter(\n",
    "            nn.init.kaiming_uniform_(\n",
    "                torch.empty(self.sae_hidden, input_dim), nonlinearity=\"relu\"\n",
    "            )\n",
    "        )\n",
    "        self.b_out = nn.Parameter(torch.zeros(input_dim))\n",
    "        self.nonlinearity = activation\n",
    "\n",
    "    def _normalize_weights(self):\n",
    "        with torch.no_grad():\n",
    "            norms = self.W_out.norm(p=2, dim=0, keepdim=True)\n",
    "            self.W_out.div_(norms)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x - self.b_out\n",
    "        acts = self.nonlinearity(x @ self.W_in + self.b_in)\n",
    "        l1_regularization = acts.abs().sum()\n",
    "        l0 = (acts > 0).sum(dim=1).float().mean()\n",
    "        self._normalize_weights()\n",
    "\n",
    "        return l0, l1_regularization, acts@self.W_out + self.b_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, test_data, batch_size=128, n_epochs=1000, l1_lam=5e-5, weight_decay=1e-4):\n",
    "    optimizer = optim.Adam(model.parameters(), weight_decay=weight_decay)\n",
    "    mse_criterion = nn.MSELoss()\n",
    "\n",
    "    n_batches = len(train_data) // batch_size\n",
    "    n_test_batches = len(test_data) // batch_size\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        total_test_loss = 0\n",
    "        total_mse_loss = 0\n",
    "        total_l1_loss = 0\n",
    "        total_l0 = 0\n",
    "        batch_perm = torch.randperm(len(train_data))\n",
    "        test_batch_perm = torch.randperm(len(test_data))\n",
    "\n",
    "        for i in range(n_batches):\n",
    "            # Training\n",
    "            idx = batch_perm[i*batch_size: (i+1)*batch_size]\n",
    "            batch = train_data[idx]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            l0, l1, recon_hiddens = model(batch)\n",
    "\n",
    "            recon_loss = mse_criterion(recon_hiddens, batch)\n",
    "            sparsity_loss = l1_lam * l1\n",
    "            loss = recon_loss + sparsity_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_l1_loss += sparsity_loss.item()\n",
    "            total_mse_loss += recon_loss.item()\n",
    "            total_l0 += l0\n",
    "\n",
    "            # Testing\n",
    "            if i < n_test_batches:\n",
    "                test_idx = test_batch_perm[i*batch_size: (i+1)*batch_size]\n",
    "                test_batch = test_data[test_idx]\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    _, _, test_recon = model(test_batch)\n",
    "                    test_loss = mse_criterion(test_recon, test_batch)\n",
    "                    total_test_loss += test_loss.item()\n",
    "\n",
    "        #if epoch % 10 == 0:\n",
    "        #    avg_loss = total_loss / n_batches\n",
    "        #    avg_test_loss = total_test_loss / n_test_batches\n",
    "        #    avg_l1_loss = total_l1_loss / n_batches\n",
    "        #    avg_l0 = total_l0 / n_batches\n",
    "            \n",
    "            #print(f'Epoch {epoch}, Loss: {avg_loss:.4f}, '\n",
    "            #      f'Test Loss: {avg_test_loss:.4f}, '\n",
    "            #      f'L1: {avg_l1_loss:.4f}, '\n",
    "            #      f'L0: {avg_l0:.4f}')\n",
    "\n",
    "    return {\n",
    "        'mse': total_mse_loss/n_batches,\n",
    "        'L0': total_l0/n_batches\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    sparsity = 128\n",
    "    hidden_dim = 128\n",
    "    width_factor = 4\n",
    "\n",
    "    data = generate_hidden_data(dim=hidden_dim, sparsity=sparsity)\n",
    "    train_size = int(0.8 * len(data))\n",
    "    train_data, test_data = data[:train_size], data[train_size:]\n",
    "    \n",
    "    relu_model = SAE(hidden_dim, width_factor, nn.ReLU())\n",
    "    print(\"Training ReLU model...\")\n",
    "    result = train(relu_model, train_data, test_data)\n",
    "            \n",
    "\n",
    "def run_DOE():\n",
    "    sparsities = [5, 10, 20, 30, 40, 50]\n",
    "    seeds = [1337, 42, 69, 420, 666]\n",
    "    results = defaultdict(list)\n",
    "    hidden_dim = 128\n",
    "    width_factor = 4\n",
    "\n",
    "    for sparsity in tqdm(sparsities):\n",
    "        for i, trial in tqdm(enumerate(range(seeds))):\n",
    "            torch.manual_seed(trial)\n",
    "            data = generate_hidden_data(dim=hidden_dim, sparsity=sparsity)\n",
    "            \n",
    "            # Shuffle data\n",
    "            indices = torch.randperm(len(data))\n",
    "            data = data[indices]\n",
    "            \n",
    "            # Split into train/test\n",
    "            train_size = int(0.8 * len(data))\n",
    "            train_data, test_data = data[:train_size], data[train_size:]\n",
    "            \n",
    "            relu_model = SAE(hidden_dim, width_factor, nn.ReLU())\n",
    "            print(f\"Training ReLU model with {sparsity} sparsity on iteration {i}\")\n",
    "            result = train(relu_model, train_data, test_data)\n",
    "            results[sparsity].append(result)\n",
    "\n",
    "    return results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 64112.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 5 sparsity on iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 64243.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 5 sparsity on iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 61952.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 5 sparsity on iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 65427.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 5 sparsity on iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 72007.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 5 sparsity on iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:27<00:00,  5.41s/it]\n",
      " 17%|█▋        | 1/6 [00:27<02:15, 27.05s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 69745.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 10 sparsity on iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 63264.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 10 sparsity on iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 64489.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 10 sparsity on iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 65591.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 10 sparsity on iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 61560.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 10 sparsity on iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:27<00:00,  5.55s/it]\n",
      " 33%|███▎      | 2/6 [00:54<01:49, 27.45s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 62560.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 20 sparsity on iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 62618.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 20 sparsity on iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 61199.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 20 sparsity on iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 64265.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 20 sparsity on iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 57146.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 20 sparsity on iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:30<00:00,  6.15s/it]\n",
      " 50%|█████     | 3/6 [01:25<01:26, 28.95s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 59653.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 30 sparsity on iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 60232.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 30 sparsity on iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 61850.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 30 sparsity on iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 62033.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 30 sparsity on iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 62120.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 30 sparsity on iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:30<00:00,  6.16s/it]\n",
      " 67%|██████▋   | 4/6 [01:56<00:59, 29.68s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 57101.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 40 sparsity on iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 60323.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 40 sparsity on iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 61314.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 40 sparsity on iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 60204.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 40 sparsity on iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 59297.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 40 sparsity on iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:31<00:00,  6.26s/it]\n",
      " 83%|████████▎ | 5/6 [02:27<00:30, 30.26s/it]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 57505.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 50 sparsity on iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 56806.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 50 sparsity on iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 56051.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 50 sparsity on iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 58029.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 50 sparsity on iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 58191.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ReLU model with 50 sparsity on iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:29<00:00,  5.95s/it]\n",
      "100%|██████████| 6/6 [02:57<00:00, 29.56s/it]\n"
     ]
    }
   ],
   "source": [
    "results = run_DOE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {5: [{'mse': 0.026843073467413586, 'L0': tensor(5.7174)},\n",
       "              {'mse': 0.026320386677980423, 'L0': tensor(5.4258)},\n",
       "              {'mse': 0.026732576079666615, 'L0': tensor(5.5404)},\n",
       "              {'mse': 0.02660268358886242, 'L0': tensor(5.7930)},\n",
       "              {'mse': 0.02716939647992452, 'L0': tensor(5.7018)}],\n",
       "             10: [{'mse': 0.044039856642484665, 'L0': tensor(10.5352)},\n",
       "              {'mse': 0.044560532396038376, 'L0': tensor(10.7474)},\n",
       "              {'mse': 0.04403712724645933, 'L0': tensor(10.8307)},\n",
       "              {'mse': 0.0442103153715531, 'L0': tensor(10.7344)},\n",
       "              {'mse': 0.0443751011043787, 'L0': tensor(10.7839)}],\n",
       "             20: [{'mse': 0.07146312793095906, 'L0': tensor(18.5846)},\n",
       "              {'mse': 0.07112449655930202, 'L0': tensor(18.4102)},\n",
       "              {'mse': 0.06989554439981778, 'L0': tensor(18.3620)},\n",
       "              {'mse': 0.0698989989856879, 'L0': tensor(18.1250)},\n",
       "              {'mse': 0.07070641467968623, 'L0': tensor(18.4831)}],\n",
       "             30: [{'mse': 0.08997719610730807, 'L0': tensor(23.6445)},\n",
       "              {'mse': 0.09024704992771149, 'L0': tensor(23.6823)},\n",
       "              {'mse': 0.08861629664897919, 'L0': tensor(23.2669)},\n",
       "              {'mse': 0.09033751239379247, 'L0': tensor(23.7878)},\n",
       "              {'mse': 0.0903093305726846, 'L0': tensor(23.8359)}],\n",
       "             40: [{'mse': 0.10431221127510071, 'L0': tensor(25.9440)},\n",
       "              {'mse': 0.1043437806268533, 'L0': tensor(26.2344)},\n",
       "              {'mse': 0.10372343535224597, 'L0': tensor(26.0234)},\n",
       "              {'mse': 0.10372344404459, 'L0': tensor(25.6979)},\n",
       "              {'mse': 0.10390087962150574, 'L0': tensor(25.6849)}],\n",
       "             50: [{'mse': 0.11511996760964394, 'L0': tensor(27.5065)},\n",
       "              {'mse': 0.11587970703840256, 'L0': tensor(27.5482)},\n",
       "              {'mse': 0.114957045763731, 'L0': tensor(27.2201)},\n",
       "              {'mse': 0.11631787816683452, 'L0': tensor(27.5625)},\n",
       "              {'mse': 0.11574999118844669, 'L0': tensor(27.1576)}]})"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
